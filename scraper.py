import requests, json, os, xml.etree.ElementTree as ET
from datetime import datetime, timedelta

GEMINI_KEY = os.getenv("GEMINI_API_KEY")
# ç›‘æ§åå•ï¼šåŒ…å«å¤§å‚åŠé«˜é¢‘å…«å¦å¯¹è±¡
COMPANIES = ['ç™¾åº¦', 'é˜¿é‡Œ', 'å­—èŠ‚', 'å°çº¢ä¹¦', 'äº¬ä¸œ', 'æ‹¼å¤šå¤š', 'è…¾è®¯', 'Google', 'AI', 'ç¾å›¢', 'ç½‘æ˜“', 'å°ç±³', 'åä¸º', 'å¿«æ‰‹', 'æ»´æ»´']

def fetch_raw():
    items = []
    # æ··åˆä¿¡æ¯æµï¼šå®˜å®£ + è´¢æŠ¥ + èŒåœºåŒ¿åçˆ†æ–™
    sources = [
        "https://rsshub.app/36kr/newsflashes",         # 36æ°ªå¿«è®¯ (å®æ—¶)
        "https://rsshub.app/cls/depth",                # è´¢è”ç¤¾æ·±åº¦ (è´¢æŠ¥/ç ”æŠ¥)
        "https://rsshub.app/xiaohongshu/user/5e5b619a000000000100788d", # æ¨¡æ‹Ÿå°çº¢ä¹¦çˆ†æ–™å·1
        "https://rsshub.app/xiaohongshu/user/5b2723904e0a4d6f8f539955", # æ¨¡æ‹Ÿå°çº¢ä¹¦çˆ†æ–™å·2
        "https://rsshub.app/wechat/msgalbum/WzExMTEx", # å¾®ä¿¡å…¬ä¼—å·ä¸“è¾‘ (ç¤ºæ„)
        "https://rsshub.app/itjuzi/invest",            # ITæ¡”å­ (æŠ•èèµ„å…«å¦)
        "https://rsshub.app/huxiu/article"             # è™å—… (æ·±åº¦/å…«å¦)
    ]
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    
    for url in sources:
        try:
            res = requests.get(url, headers=headers, timeout=25)
            if res.status_code != 200: continue
            root = ET.fromstring(res.text)
            for item in root.findall('./channel/item'):
                title = item.find('title').text or ""
                link = item.find('link').text or ""
                desc = item.find('description').text or ""
                
                # å…³é”®è¯åŒ¹é…ï¼šæ ‡é¢˜æˆ–æ­£æ–‡åŒ…å«å¤§å‚å
                matched = [co for co in COMPANIES if co.lower() in (title + desc).lower()]
                if matched:
                    items.append({
                        "title": title, 
                        "link": link, 
                        "raw_content": desc[:300], # æä¾›ç»™AIåˆ¤æ–­
                        "source_url": url
                    })
        except: continue
    return items

def ai_process(items):
    if not GEMINI_KEY or not items: return []
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_KEY}"
    
    # å¢å¼ºç‰ˆ Promptï¼šè¦æ±‚ AI è¯†åˆ«å¹¶å»é‡å…«å¦
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªç²¾é€šäº’è”ç½‘å¤§å‚å…«å¦å’Œè´¢æŠ¥çš„åˆ†æå¸ˆã€‚è¯·å¤„ç†ä»¥ä¸‹ç¢ç‰‡ä¿¡æ¯ï¼š
    1. åˆ¤é‡ï¼šå¤šæ¸ é“æŠ¥é“çš„åŒä¸€ä»¶äº‹ï¼ˆå°¤å…¶æ˜¯è£å‘˜ã€æ¶¨è–ªã€å‘å¸ƒä¼šã€è´¢æŠ¥ï¼‰å¿…é¡»åˆå¹¶ä¸ºä¸€æ¡ã€‚
    2. åˆ†ç±»ï¼šä» [è–ªé…¬èŒçº§ğŸ’°, ç»„ç»‡å˜åŒ–ğŸ¢, ä¸šåŠ¡åŠ¨æ€ğŸ“¡, è´¢æŠ¥ç ”æŠ¥ğŸ“ˆ, å‘å¸ƒä¼šğŸš€, å°é“æ¶ˆæ¯ğŸ¤«] ä¸­é€‰ä¸€ã€‚
    3. æå–ï¼šè¯†åˆ«æ ¸å¿ƒå…¬å¸ã€‚
    4. è¿‡æ»¤ï¼šå‰”é™¤çº¯å¹¿å‘Šã€æ— å…³ç´§è¦çš„æ—¥å¸¸ä¿ƒé”€ã€‚
    è¿”å›ä¸¥æ ¼JSONæ ¼å¼æ•°ç»„(å­—æ®µ:company, category, content, link)ã€‚
    æ•°æ®ï¼š{json.dumps(items[:40], ensure_ascii=False)}
    """
    
    try:
        res = requests.post(url, json={"contents": [{"parts": [{"text": prompt}]}]}, timeout=30)
        text = res.json()['candidates'][0]['content']['parts'][0]['text']
        return json.loads(text.replace('```json', '').replace('```', '').strip())
    except: return []

if __name__ == "__main__":
    raw = fetch_raw()
    processed = ai_process(raw)
    today = datetime.now().strftime("%Y-%m-%d")
    for item in processed: item['date'] = today
        
    data_file = 'data.json'
    old_data = []
    if os.path.exists(data_file):
        with open(data_file, 'r', encoding='utf-8') as f:
            try: old_data = json.load(f)
            except: old_data = []

    # é€»è¾‘åˆ¤é‡ï¼šæ ¹æ®å†…å®¹æ–‡æœ¬åˆ¤å®š
    seen_contents = {i.get('content') for i in old_data}
    new_entries = [i for i in processed if i.get('content') not in seen_contents]
    
    final_list = new_entries + old_data
    # ä»…ä¿ç•™æœ€è¿‘7å¤©
    limit_date = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
    final_list = [i for i in final_list if i.get('date', '') >= limit_date]
    final_list.sort(key=lambda x: (x.get('date', ''), x.get('company', '')), reverse=True)

    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump(final_list, f, ensure_ascii=False, indent=4)
